# QAT Training Workflow

## Complete Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ECG_MIT_BIH.ipynb                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  Cell 1-10:  Setup & Configuration                             â”‚
â”‚              â”œâ”€â”€ Import libraries                               â”‚
â”‚              â”œâ”€â”€ Load data                                      â”‚
â”‚              â”œâ”€â”€ Define model                                   â”‚
â”‚              â””â”€â”€ Setup optimizer                                â”‚
â”‚                                                                  â”‚
â”‚  Cell 10.5:  â­ ENABLE QAT (CRITICAL!)                          â”‚
â”‚              â”œâ”€â”€ Define qat_policy                              â”‚
â”‚              â”œâ”€â”€ ai8x.initiate_qat(model, qat_policy)          â”‚
â”‚              â””â”€â”€ Fold BatchNorm automatically                   â”‚
â”‚                                                                  â”‚
â”‚  Cell 11:    Training Loop                                      â”‚
â”‚              â””â”€â”€ Model learns with quantization                 â”‚
â”‚                                                                  â”‚
â”‚  Cell 12-13: Evaluation & Save                                  â”‚
â”‚              â””â”€â”€ Save: best_ecg_model_ai8x.pth.tar             â”‚
â”‚                                                                  â”‚
â”‚  New Cell:   Verify BatchNorm Folding                          â”‚
â”‚              â”œâ”€â”€ Check: No .bn. keys âœ…                         â”‚
â”‚              â”œâ”€â”€ Check: QAT parameters exist âœ…                 â”‚
â”‚              â””â”€â”€ Display: Ready for synthesis ğŸ‰                â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Copy to ai8x-synthesis directory                    â”‚
â”‚  â”œâ”€â”€ best_ecg_model_ai8x.pth.tar                               â”‚
â”‚  â”œâ”€â”€ sample_ecg_1x128.npy                                      â”‚
â”‚  â””â”€â”€ ecg-net.yaml                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Quantization (quantize.py)                    â”‚
â”‚  Input:  best_ecg_model_ai8x.pth.tar (QAT checkpoint)          â”‚
â”‚  Output: best_ecg_model_ai8x_q8.pth.tar (8-bit weights)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Synthesis (ai8xize.py)                         â”‚
â”‚  Input:  best_ecg_model_ai8x_q8.pth.tar + ecg-net.yaml         â”‚
â”‚  Output: C code for MAX78002                                    â”‚
â”‚          â”œâ”€â”€ cnn.c                                              â”‚
â”‚          â”œâ”€â”€ cnn.h                                              â”‚
â”‚          â”œâ”€â”€ weights.h                                          â”‚
â”‚          â””â”€â”€ main.c                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Build & Deploy                                â”‚
â”‚  make && make flash â†’ MAX78002 Hardware                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Key Decision Points

```
Training Start
      â”‚
      â–¼
Did you run Cell 10.5? â”€â”€NOâ”€â”€> âŒ STOP! Run Cell 10.5 first
      â”‚
     YES
      â”‚
      â–¼
Training Complete
      â”‚
      â–¼
Run Verification Cell
      â”‚
      â”œâ”€â”€> BatchNorm folded? â”€â”€NOâ”€â”€> âŒ Re-train with Cell 10.5
      â”‚           â”‚
      â”‚          YES
      â”‚           â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼
            QAT params exist? â”€â”€NOâ”€â”€> âš ï¸ Re-train recommended
                  â”‚
                 YES
                  â”‚
                  â–¼
            âœ… Ready for synthesis!
                  â”‚
                  â–¼
            Copy to ai8x-synthesis
                  â”‚
                  â–¼
            Quantize â†’ Synthesize â†’ Deploy
```

## What Happens With vs Without QAT

```
WITHOUT QAT (OLD WAY - BROKEN):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Training â†’ Save Checkpoint
              â”‚
              â”œâ”€â”€ Contains: conv1.weight âœ…
              â”œâ”€â”€ Contains: conv1.bias âœ…
              â”œâ”€â”€ Contains: conv1.bn.weight âŒ (Problem!)
              â””â”€â”€ Contains: conv1.bn.bias âŒ (Problem!)
              â”‚
              â–¼
        ai8xize.py
              â”‚
              â–¼
        âŒ ERROR: "Ensure the BatchNorm layers have been folded"


WITH QAT (NEW WAY - WORKS):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Training with QAT â†’ Save Checkpoint
              â”‚
              â”œâ”€â”€ Contains: conv1.weight âœ… (includes BatchNorm)
              â”œâ”€â”€ Contains: conv1.bias âœ… (includes BatchNorm)
              â”œâ”€â”€ Contains: conv1.weight_bits âœ… (QAT parameter)
              â””â”€â”€ Contains: conv1.output_shift âœ… (QAT parameter)
              â”‚
              â–¼
        ai8xize.py
              â”‚
              â–¼
        âœ… SUCCESS: C code generated!
```

## Memory Map: Before vs After QAT

```
BEFORE QAT:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Model Layer: Conv1d â†’ BatchNorm â†’ ReLU
               â†“          â†“
           Separate   Separate
           Weights    Parameters
               
           âŒ Two operations in hardware
           âŒ More memory needed
           âŒ Synthesis fails


AFTER QAT:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Model Layer: Conv1d(with fused BN) â†’ ReLU
                      â†“
                  Combined
                  Weights
                  
           âœ… One operation in hardware
           âœ… Less memory needed
           âœ… Synthesis succeeds
```

## Checkpoint Contents Comparison

```
NON-QAT CHECKPOINT:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
state_dict:
  conv1.op.weight        â† Conv weights
  conv1.op.bias          â† Conv bias
  conv1.bn.weight        â† BatchNorm gamma âŒ
  conv1.bn.bias          â† BatchNorm beta âŒ
  conv1.bn.running_mean  â† BatchNorm stats âŒ
  conv1.bn.running_var   â† BatchNorm stats âŒ


QAT CHECKPOINT:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
state_dict:
  conv1.op.weight        â† Fused weights (Conv + BN) âœ…
  conv1.op.bias          â† Fused bias (Conv + BN) âœ…
  conv1.weight_bits      â† QAT quantization config âœ…
  conv1.bias_bits        â† QAT quantization config âœ…
  conv1.output_shift     â† QAT scaling factor âœ…
  conv1.shift_quantile   â† QAT parameter âœ…
```

## Timeline: Your Journey

```
PAST (What Happened):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1. Trained model without Cell 10.5
2. Saved checkpoint with unfused BatchNorm
3. Tried synthesis â†’ ERROR âŒ


PRESENT (What We Did):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1. Added Cell 10.5 to enable QAT âœ…
2. Added verification cell âœ…
3. Updated SYNTHESIS_INSTRUCTIONS.md âœ…


FUTURE (What You'll Do):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1. Re-run training from Cell 1
2. Execute Cell 10.5 before Cell 11
3. Verify checkpoint â†’ âœ… SUCCESS
4. Follow synthesis instructions
5. Deploy to MAX78002 â†’ ğŸ‰
```
